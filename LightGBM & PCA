＃必要ライブラリ
import numpy as np
import pandas as pd

＃データのインポート
Train_set = pd.read_csv('Training_dataset.csv')
Test_set = pd.read_csv("Test_dataset.csv")

x_train = Train_set.iloc[:,0:30]
y_train = Train_set[["Flag"]]
x_test = Test_set.iloc[:,0:30]
y_test = Test_set[["Flag"]]

＃lightgbmのインポート
import lightgbm as lgbm

callbacks = [
    lgbm.callback.early_stopping(stopping_rounds=30,)
]

clf = lgbm.LGBMClassifier(
    objective='binary',
    random_state=42,
    n_estimators=10000,
    learning_rate=0.1,
      num_leaves=63
)
clf.fit(x_train, y_train,
        eval_set=(x_test, y_test),
        callbacks=callbacks,
          eval_metric='average_precision',
       )

＃作図用ライブラリ
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns

#予測式作成
y_pred = clf.predict(x_test)

#accuracy算出
accuracy = accuracy_score(y_pred, y_test)
print(f"accuracy score: {accuracy:0.4f}")

#混同行列(Confusion Matrix) の作成
cm = confusion_matrix(y_test, y_pred)
cm_matrix = pd.DataFrame(data=cm, columns=['Predict Positive:1', 'Predict Negative:0'],
                                 index=['Actual Positive:1', 'Actual Negative:0'])
sns.heatmap(cm_matrix,annot=True, cmap='Blues')

#PCAに必要なライブラリ
import matplotlib.pyplot as plt
import sklearn
from sklearn.decomposition import PCA

df = Train_set.drop('SubID', axis=1)

from pandas import plotting
plotting.scatter_matrix(df.iloc[:, 0:5], figsize=(8, 8), c=list(df.iloc[:, 30]), alpha=0.5)
plt.show()

dfs.head()

pca = PCA()
pca.fit(dfs)
feature = pca.transform(dfs)

pd.DataFrame(feature, columns=["PC{}".format(x + 1) for x in range(len(dfs.columns))]).head()

plt.figure(figsize=(6, 6))
plt.scatter(feature[:, 0], feature[:, 1], alpha=0.8, c=list(df.iloc[:, 30]))
plt.grid()
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()

from pandas import plotting
plotting.scatter_matrix(pd.DataFrame(feature,
                        columns=["PC{}".format(x + 1) for x in range(len(dfs.columns))]),
                        figsize=(64, 64), c=list(df.iloc[:, 0]), alpha=0.5)
plt.show()

pd.DataFrame(pca.explained_variance_ratio_, index=["PC{}".format(x + 1) for x in range(len(dfs.columns))])

import matplotlib.ticker as ticker
plt.gca().get_xaxis().set_major_locator(ticker.MaxNLocator(integer=True))
plt.plot([0] + list( np.cumsum(pca.explained_variance_ratio_)), "-o")
plt.xlabel("Number of principal components")
plt.ylabel("Cumulative contribution rate")
plt.grid()
plt.show()

plt.figure(figsize=(6, 6))
for x, y, name in zip(pca.components_[0], pca.components_[1], df.columns[1:]):
    plt.text(x, y, name)
plt.scatter(pca.components_[0], pca.components_[1], alpha=0.8)
plt.grid()
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()
