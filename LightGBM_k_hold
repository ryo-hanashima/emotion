import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import roc_curve

!pip install optuna

from optuna.integration import lightgbm as lgb

Train_set = pd.read_csv('Training_dataset.csv')
Test_set = pd.read_csv("Test_dataset.csv")

x_train = Train_set.iloc[:,0:30]
y_train = Train_set[["Flag"]]
x_test = Test_set.iloc[:,0:30]
y_test = Test_set[["Flag"]]

def standard_p(p, ddof = 1):
  #最小値の計算
  mean_p = p.mean()
  #最大値の計算
  std_p = p.std(ddof = ddof)
  #標準化の計算
  standard_p = (p - mean_p) / (std_p)
  return standard_p

x_train_s= standard_p(x_train)
x_test_s= standard_p(x_test)

import sklearn
from sklearn.decomposition import PCA

pca = PCA(n_components=3)
x_test_s = pca.fit_transform(x_test_s.iloc[:,:-1])
x_test_s = pd.DataFrame(x_test_s)
x_test_s.head()

from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error

kf = KFold(n_splits=5, shuffle=True, random_state=100)
valid_scores = []
models = []

for fold, (train_indices, valid_indices) in enumerate(kf.split(x_train_s)):
    X_train, X_valid = x_train_s.iloc[train_indices], x_train_s.iloc[valid_indices]
    Y_train, Y_valid = y_train.iloc[train_indices], y_train.iloc[valid_indices]
    lgb_train = lgb.Dataset(X_train, Y_train)
    lgb_eval = lgb.Dataset(X_valid, Y_valid)

    print("fold No. = ", fold)
    param = {
        'objective': 'binary',
        'metric': 'auc',
        'verbosity': -1,
        'boosting_type': 'gbdt',
         'verbose': -1,
         'random_seed':42
    }
    verbose_eval = 0

    evaluation_results = {}
    model = lgb.train(param,
                 lgb_train,valid_sets=lgb_train)
    print("now caluculating MAE values .....")
    Y_valid_pred = model.predict(X_valid)
    score = mean_absolute_error(Y_valid, Y_valid_pred)
    print(f'fold {fold} MAE: {score}')
    print(model.best_score)
    valid_scores.append(score)

    fpr, tpr, thresholds = roc_curve(Y_valid, Y_valid_pred, drop_intermediate=False,)
    youden_index = np.argmax((1-fpr)+tpr)
    thresh = thresholds[youden_index]
    print(f"thresh: {thresh}")

    y_pred = model.predict(x_test_s, num_iteration=model.best_iteration)
    y_pred = y_pred.round(0)
    accuracy = accuracy_score(y_pred, y_test)
    print(f"accuracy score: {accuracy:0.4f}")


    models.append(model)

y_pred = model.predict(x_test_s, num_iteration=model.best_iteration)
y_pred = y_pred.round(0)

accuracy = accuracy_score(y_pred, y_test)
print(f"accuracy score: {accuracy:0.4f}")

cm = confusion_matrix(y_test, y_pred)

cm_matrix = pd.DataFrame(data=cm, columns=['Predict Positive:1', 'Predict Negative:0'],
                                 index=['Actual Positive:1', 'Actual Negative:0'])

sns.heatmap(cm_matrix,annot=True, cmap='Blues')

params = {
        'objective': 'binary',
        'metric': 'auc',
        'verbosity': -1,
        'boosting_type': 'gbdt',
         'verbose': -1,
         'random_seed':42
        }
verbose_eval = 0


lgb_train = lgb.Dataset(x_train_s, y_train)
lgb_eval = lgb.Dataset(x_test_s, y_test, reference=lgb_train)

tuner = lgb.LightGBMTunerCV(params, lgb_train, folds=KFold(n_splits=5))

tuner.run()

best_params = tuner.best_params
print("  Params: ")
for key, value in best_params.items():
    print("    {}: {}".format(key, value))

model = lgb.train(best_params, lgb_train, valid_sets=lgb_eval)

y_pred = model.predict(x_test_s, num_iteration=model.best_iteration)
y_pred = y_pred.round(0)

accuracy = accuracy_score(y_pred, y_test)
print(f"accuracy score: {accuracy:0.4f}")

cm = confusion_matrix(y_test, y_pred)

cm_matrix = pd.DataFrame(data=cm, columns=['Predict Positive:1', 'Predict Negative:0'],
                                 index=['Actual Positive:1', 'Actual Negative:0'])

sns.heatmap(cm_matrix,annot=True, cmap='Blues')


